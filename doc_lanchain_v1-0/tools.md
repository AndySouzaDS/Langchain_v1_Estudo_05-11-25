Componentes principais

# **Tools**

Muitas aplica√ß√µes de IA interagem com os usu√°rios por meio de linguagem natural. 

No entanto, alguns casos de uso exigem que os modelos interajam diretamente com **sistemas externos ‚Äî como APIs, bancos de dados ou sistemas de arquivos** ‚Äî usando entradas estruturadas.

> As tools s√£o componentes que [os agentes](https://docs.langchain.com/oss/python/langchain/agents) chamam para executar a√ß√µes.

Elas ampliam as capacidades do modelo, permitindo que ele interaja com o mundo por meio de entradas e sa√≠das bem definidas.

> As tools encapsulam uma fun√ß√£o invoc√°vel e seu esquema de entrada.

Esses elementos podem ser passados para [modelos de chat](https://docs.langchain.com/oss/python/langchain/models) compat√≠veis, permitindo que o modelo decida se deve invocar uma tool e com quais argumentos.

Nesses cen√°rios, a chamada de tools permite que os modelos gerem solicita√ß√µes que estejam em conformidade com um esquema de entrada especificado.

üìå **Uso de tools do lado do servidor**

Alguns modelos de chat (por exemplo, [OpenAI](https://docs.langchain.com/oss/python/integrations/chat/openai) , [Anthropic](https://docs.langchain.com/oss/python/integrations/chat/anthropic) e [Gemini](https://docs.langchain.com/oss/python/integrations/chat/google_generative_ai) ) possuem [tools integradas](https://docs.langchain.com/oss/python/langchain/models#server-side-tool-use) que s√£o executadas no servidor, como mecanismos de busca na web e interpretadores de c√≥digo. Consulte a [vis√£o geral do provedor](https://docs.langchain.com/oss/python/integrations/providers/overview) para saber como acessar essas tools com o seu modelo de chat espec√≠fico.

### üìö Defini√ß√£o b√°sica da ferramenta

A maneira mais simples de criar uma ferramenta √© com o **decorador** [`@tool`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.tool).

Por padr√£o, a **docstring da fun√ß√£o se torna a descri√ß√£o da ferramenta**, ajudando o modelo a entender quando us√°-la:

```python
from langchain.tools import tool

@tool
def search_database(query: str, limit: int = 10) -> str:
    """Pesquise no banco de dados de clientes por registros que correspondam √† consulta.

Args:
    query: Termos de pesquisa
    limit: N√∫mero m√°ximo de resultados a serem retornados
    """
    return f"Encontre {limit} resultados para '{query}'"
```

As **dicas de tipo s√£o necess√°rias**, pois definem o esquema de entrada da ferramenta.

**A docstring deve ser informativa e concisa para ajudar o modelo a entender a finalidade da ferramenta.**

### üìå Personalizar propriedades da ferramenta

#### **‚úÖ Nome da ferramenta personalizada**

Por padr√£o, **o nome da ferramenta deriva do nome da fun√ß√£o**. Altere-o se precisar de algo mais descritivo:

```python
@tool("web_search")  # nome customizado
def search(query: str) -> str:
    """Busque na web por informa√ß√µes."""
    return f"Resultados para: {query}"

print(search.name)  # ferramementa pesquisa web
```

### **‚úÖ Descri√ß√£o de tools personalizada**

Substitua a descri√ß√£o da ferramenta gerada automaticamente para obter orienta√ß√µes mais claras sobre o modelo:

```python
@tool("calculator", description="Realiza c√°lculos aritm√©ticos. Use esta ferramenta para qualquer problema matem√°tico.")
def calc(expression: str) -> str:
    """Avalia express√µes matem√°ticas."""
    return str(eval(expression))
```

### ‚úÖ Defini√ß√£o de esquema avan√ßado

Defina entradas complexas com modelos Pydantic ou esquemas JSON:

#### **üìå Modelo Pydantic**

```python
from pydantic import BaseModel, Field
from typing import Literal

class WeatherInput(BaseModel):
    """Entrada para consultas meteorol√≥gicas."""
    location: str = Field(description="Nome da cidade ou coordenadas.")
    units: Literal["celsius", "fahrenheit"] = Field(
        default="celsius",
        description="Prefer√™ncia de unidade de temperatura."
    )
    include_forecast: bool = Field(
        default=False,
        description="Include 5-day forecast"
    )

@tool(args_schema=WeatherInput)
def get_weather(location: str, units: str = "celsius", include_forecast: bool = False) -> str:
    """Veja as condi√ß√µes meteorol√≥gicas atuais e a previs√£o opcional."""
    temp = 22 if units == "celsius" else 72
    result = f"Condi√ß√µes meteorol√≥gicas atuais em {location}: {temp} graus {units[0].upper()}"
    if include_forecast:
        result += "\nPr√≥ximos 5 dias: Ensolarado"
    return result
```

#### **üìå Esquema JSON**

```python
weather_schema = {
    "type": "object",
    "properties": {
        "location": {"type": "string"},
        "units": {"type": "string"},
        "include_forecast": {"type": "boolean"}
    },
    "required": ["location", "units", "include_forecast"]
}

@tool(args_schema=weather_schema)
def get_weather(location: str, units: str = "celsius", include_forecast: bool = False) -> str:
    """Veja as condi√ß√µes meteorol√≥gicas atuais e a previs√£o opcional."""
    temp = 22 if units == "celsius" else 72
    result = f"Condi√ß√µes meteorol√≥gicas atuais em {location}: {temp} graus {units[0].upper()}"
    if include_forecast:
        result += "\nPr√≥ximos 5 dias: Ensolarado"
    return result
```

### üí° Acessando o contexto

> **Por que isso √© importante:**

As tools s√£o mais poderosas quando podem acessar o estado do agente, o contexto de tempo de execu√ß√£o e a mem√≥ria de longo prazo. Isso permite que as tools tomem decis√µes contextuais, personalizem respostas e mantenham informa√ß√µes ao longo das conversas.

O contexto de tempo de execu√ß√£o oferece uma maneira de injetar depend√™ncias (como conex√µes de banco de dados, IDs de usu√°rio ou configura√ß√µes) em suas tools em tempo de execu√ß√£o, tornando-as mais test√°veis e reutiliz√°veis.

As tools podem acessar informa√ß√µes de tempo de execu√ß√£o por meio do par√¢metro `ToolRuntime`, que fornece:

- **Estado** - Dados mut√°veis que fluem durante a execu√ß√£o (ex.: mensagens, contadores, campos personalizados).

- **Contexto** - Configura√ß√£o imut√°vel, como IDs de usu√°rio, detalhes da sess√£o ou configura√ß√£o espec√≠fica do aplicativo.

- **Armazenar** - Mem√≥ria persistente de longo prazo entre conversas.

- **Stream Writer** - Transmita atualiza√ß√µes personalizadas √† medida que as tools s√£o executadas.
- **Configura√ß√£o** - `RunnableConfig`para a execu√ß√£o.

- **ID da chamada da ferramenta** - ID da chamada da ferramenta atual.

### üìå `ToolRuntime`

Utilize `ToolRuntime` para acessar todas as informa√ß√µes de tempo de execu√ß√£o em um √∫nico par√¢metro. Basta adicion√°-lo `runtime: ToolRuntime` √† assinatura da sua ferramenta e ele ser√° injetado automaticamente sem ser exposto ao LLM.

‚úÖ **`ToolRuntime`**

Um par√¢metro unificado que fornece √†s tools acesso ao estado, contexto, armazenamento, streaming, configura√ß√£o e ID da chamada da ferramenta. 

Isso substitui o padr√£o antigo de [`InjectedState`](https://reference.langchain.com/python/langgraph/agents/#langgraph.prebuilt.tool_node.InjectedState) usar [`InjectedStore`](https://reference.langchain.com/python/langgraph/agents/#langgraph.prebuilt.tool_node.InjectedStore) anota√ß√µes [`get_runtime`](https://reference.langchain.com/python/langgraph/runtime/#langgraph.runtime.get_runtime) separadas [`InjectedToolCallId`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.InjectedToolCallId).

O ambiente de execu√ß√£o fornece automaticamente essas funcionalidades √†s suas fun√ß√µes de ferramenta, sem que voc√™ precise pass√°-las explicitamente ou usar estado global.

#### **Acessando o estado:** 

As tools podem acessar o estado atual do grafo usando `ToolRuntime`:

```python
from langchain.tools import tool, ToolRuntime

# Access the current conversation state
@tool
def summarize_conversation(
    runtime: ToolRuntime
) -> str:
    """Summarize the conversation so far."""
    messages = runtime.state["messages"]

    human_msgs = sum(1 for m in messages if m.__class__.__name__ == "HumanMessage")
    ai_msgs = sum(1 for m in messages if m.__class__.__name__ == "AIMessage")
    tool_msgs = sum(1 for m in messages if m.__class__.__name__ == "ToolMessage")

    return f"Conversation has {human_msgs} user messages, {ai_msgs} AI responses, and {tool_msgs} tool results"

# Access custom state fields
@tool
def get_user_preference(
    pref_name: str,
    runtime: ToolRuntime  # ToolRuntime parameter is not visible to the model
) -> str:
    """Get a user preference value."""
    preferences = runtime.state.get("user_preferences", {})
    return preferences.get(pref_name, "Not set")
```

O par√¢metro `tool_runtime` est√° oculto no modelo. No exemplo acima, o modelo s√≥ v√™ o par√¢metro `pref_name` no esquema da ferramenta ‚Äî `tool_runtime` ele *n√£o* est√° inclu√≠do na solicita√ß√£o.

#### **Atualizando estado:** Utilize [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) para atualizar o estado do agente ou controlar o fluxo de execu√ß√£o do grafo:

```python
from langgraph.types import Command
from langchain.messages import RemoveMessage
from langgraph.graph.message import REMOVE_ALL_MESSAGES
from langchain.tools import tool, ToolRuntime

# Update the conversation history by removing all messages
@tool
def clear_conversation() -> Command:
    """Clear the conversation history."""

    return Command(
        update={
            "messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)],
        }
    )

# Update the user_name in the agent state
@tool
def update_user_name(
    new_name: str,
    runtime: ToolRuntime
) -> Command:
    """Update the user's name."""
    return Command(update={"user_name": new_name})
```

### Contexto

Acesse configura√ß√µes imut√°veis e dados contextuais, como IDs de usu√°rio, detalhes da sess√£o ou configura√ß√µes espec√≠ficas do aplicativo por meio de `runtime.context`. As tools podem acessar o contexto de tempo de execu√ß√£o atrav√©s de `ToolRuntime`:

```python
from dataclasses import dataclass
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime

USER_DATABASE = {
    "user123": {
        "name": "Alice Johnson",
        "account_type": "Premium",
        "balance": 5000,
        "email": "alice@example.com"
    },
    "user456": {
        "name": "Bob Smith",
        "account_type": "Standard",
        "balance": 1200,
        "email": "bob@example.com"
    }
}

@dataclass
class UserContext:
    user_id: str

@tool
def get_account_info(runtime: ToolRuntime[UserContext]) -> str:
    """Get the current user's account information."""
    user_id = runtime.context.user_id

    if user_id in USER_DATABASE:
        user = USER_DATABASE[user_id]
        return f"Account holder: {user['name']}\nType: {user['account_type']}\nBalance: ${user['balance']}"
    return "User not found"

model = ChatOpenAI(model="gpt-4o")
agent = create_agent(
    model,
    tools=[get_account_info],
    context_schema=UserContext,
    system_prompt="You are a financial assistant."
)

result = agent.invoke(
    {"messages": [{"role": "user", "content": "What's my current balance?"}]},
    context=UserContext(user_id="user123")
)
```

### Mem√≥ria (Armazenamento)

Acesse dados persistentes entre conversas usando o reposit√≥rio. O reposit√≥rio √© acessado via [inserir caminho aqui] `runtime.store`e permite salvar e recuperar dados espec√≠ficos do usu√°rio ou do aplicativo. As tools podem acessar e atualizar o armazenamento atrav√©s de `ToolRuntime`:

```python
from typing import Any
from langgraph.store.memory import InMemoryStore
from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime

# Access memory
@tool
def get_user_info(user_id: str, runtime: ToolRuntime) -> str:
    """Look up user info."""
    store = runtime.store
    user_info = store.get(("users",), user_id)
    return str(user_info.value) if user_info else "Unknown user"

# Update memory
@tool
def save_user_info(user_id: str, user_info: dict[str, Any], runtime: ToolRuntime) -> str:
    """Save user info."""
    store = runtime.store
    store.put(("users",), user_id, user_info)
    return "Successfully saved user info."

store = InMemoryStore()
agent = create_agent(
    model,
    tools=[get_user_info, save_user_info],
    store=store
)

# First session: save user info
agent.invoke({
    "messages": [{"role": "user", "content": "Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev"}]
})

# Second session: get user info
agent.invoke({
    "messages": [{"role": "user", "content": "Get user info for user with id 'abc123'"}]
})
# Here is the user info for user with ID "abc123":
# - Name: Foo
# - Age: 25
# - Email: foo@langchain.dev
```

Veja todas as 42 linhas

### Stream Writer

Transmita atualiza√ß√µes personalizadas de tools √† medida que elas s√£o executadas `runtime.stream_writer`. Isso √© √∫til para fornecer feedback em tempo real aos usu√°rios sobre o que uma ferramenta est√° fazendo.

```python
from langchain.tools import tool, ToolRuntime

@tool
def get_weather(city: str, runtime: ToolRuntime) -> str:
    """Get weather for a given city."""
    writer = runtime.stream_writer

    # Stream custom updates as the tool executes
    writer(f"Looking up data for city: {city}")
    writer(f"Acquired data for city: {city}")

    return f"It's always sunny in {city}!"
```

Se voc√™ usar `runtime.stream_writer`o LangGraph dentro da sua ferramenta, ela dever√° ser invocada em um contexto de execu√ß√£o do LangGraph. Consulte [a se√ß√£o Streaming](https://docs.langchain.com/oss/python/langchain/streaming) para obter mais detalhes.

---

[Edite o c√≥digo-fonte desta p√°gina no GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/tools.mdx)

[Conecte esses documentos programaticamente](https://docs.langchain.com/use-these-docs) ao Claude, VSCode e outros softwares via MCP para obter respostas em tempo real.